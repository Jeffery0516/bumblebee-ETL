etlAgent.sources = src1
etlAgent.sinks = sink1

# Describe/configure the source
etlAgent.sources.src1.type = org.apache.flume.source.kafka.KafkaSource
etlAgent.sources.src1.kafka.topics=dpistream
etlAgent.sources.src1.kafka.consumer.group.id=flume170204
etlAgent.sources.src1.kafka.bootstrap.servers=kfk80:9091,kfk80:9092,kfk80:9093,kfk80:9094,kfk81:9091,kfk81:9092,kfk81:9093,kfk81:9094,kfk82:9091,kfk82:9092,kfk82:9093,kfk82:9094,kfk67:9091,kfk67:9092,kfk67:9093,kfk67:9094,kfk72:9091,kfk72:9092,kfk72:9093,kfk72:9094
etlAgent.sources.src1.batchSize=5000

etlAgent.sources.src1.interceptors = gzDPIInterceptor
etlAgent.sources.src1.interceptors.gzDPIInterceptor.type = com.gsta.bigdata.etl.flume.GZDPIInterceptor$Builder
etlAgent.sources.src1.interceptors.gzDPIInterceptor.fields=ts,ad,srcip,srcport,dstip,dstport,url,host,path,query,domain,ref,ua,cookie,weixinid,qq,buy_uin,taobao_nick,weibosup,weiboname,weibonick,dpihour,timeStamp,dpiday,collectHost
#etlAgent.sources.src1.interceptors.gzDPIInterceptor.delimiter=\\|
etlAgent.sources.src1.interceptors.gzDPIInterceptor.delimiter=\001
etlAgent.sources.src1.interceptors.gzDPIInterceptor.headerFields=dpiday,dpihour
etlAgent.sources.src1.interceptors.gzDPIInterceptor.processId=true

# Describe the sink
etlAgent.sinks.sink1.type = hdfs
etlAgent.sinks.sink1.hdfs.path=/data/adpi/tmp/%{dpiday}/%{dpihour}/
etlAgent.sinks.sink1.hdfs.filePrefix=dpi.%{processId}
etlAgent.sinks.sink1.hdfs.fileSuffix=.lzo
#4G file size
etlAgent.sinks.sink1.hdfs.rollSize=4294967296
etlAgent.sinks.sink1.hdfs.rollInterval=0
etlAgent.sinks.sink1.hdfs.idleTimeout=120
#don't use record count
etlAgent.sinks.sink1.hdfs.rollCount=0
etlAgent.sinks.sink1.hdfs.batchSize=5000
etlAgent.sinks.sink1.hdfs.fileType=CompressedStream  
etlAgent.sinks.sink1.hdfs.codeC=lzop
etlAgent.sinks.sink1.hdfs.writeFormat=Text
etlAgent.sinks.sink1.hdfs.callTimeout=60000

# Use a channel which buffers events in memory
etlAgent.channels = ch1
etlAgent.channels.ch1.type = memory
etlAgent.channels.ch1.capacity = 10000
etlAgent.channels.ch1.transactionCapacity = 10000
etlAgent.channels.ch1.keep-alive = 60

# Bind the source and sink to the channel
etlAgent.sources.src1.channels = ch1
etlAgent.sinks.sink1.channel = ch1
