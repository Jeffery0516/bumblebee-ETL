etlAgent.sources = src1
etlAgent.sinks = sink1

# Describe/configure the source
etlAgent.sources.src1.type = spooldir
etlAgent.sources.src1.spoolDir = /home/tianxq/etl/ztedata
etlAgent.sources.src1.batchSize=1000
#etlAgent.sources.src1.interceptors = etlInterceptor host
etlAgent.sources.src1.interceptors = etlInterceptor

etlAgent.sources.src1.interceptors.etlInterceptor.type = com.gsta.bigdata.etl.FlumeMROInterceptor$Builder
etlAgent.sources.src1.interceptors.etlInterceptor.configFile=./conf/gdnoce/etl-mro-zte2016-nodim.xml
etlAgent.sources.src1.interceptors.etlInterceptor.timeStampHeader = timeStamp
etlAgent.sources.src1.interceptors.etlInterceptor.eNodeIdHeader = eNodeId
etlAgent.sources.src1.interceptors.etlInterceptor.fileCount = 500

#/user/tianxq/flume/mrdata.BDI069.1467704079349.txt
#etlAgent.sources.src1.interceptors.host.type=org.apache.flume.interceptor.HostInterceptor$Builder 
#etlAgent.sources.src1.interceptors.host.useIP = false 
#etlAgent.sources.src1.interceptors.host.hostHeader =  hostname

# Describe the sink
etlAgent.sinks.sink1.type = hdfs
etlAgent.sinks.sink1.hdfs.path=/user/tianxq/flume
#etlAgent.sinks.sink1.hdfs.filePrefix=mrdata.%{hostname} 
etlAgent.sinks.sink1.hdfs.filePrefix=mrdata.%{timeStamp}.%{eNodeId}
etlAgent.sinks.sink1.hdfs.fileSuffix=.txt
etlAgent.sinks.sink1.hdfs.rollSize=1073741824
etlAgent.sinks.sink1.hdfs.rollCount=0
etlAgent.sinks.sink1.hdfs.batchSize=1000
etlAgent.sinks.sink1.hdfs.fileType=DataStream 
etlAgent.sinks.sink1.hdfs.writeFormat=Text

# Use a channel which buffers events in memory
etlAgent.channels = ch1
etlAgent.channels.ch1.type = memory
etlAgent.channels.ch1.capacity = 10000
etlAgent.channels.ch1.transactionCapacity = 10000

# Bind the source and sink to the channel
etlAgent.sources.src1.channels = ch1
etlAgent.sinks.sink1.channel = ch1