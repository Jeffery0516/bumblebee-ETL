etlAgent.sources = src1
etlAgent.sinks = sink1

# Describe/configure the source
#etlAgent.sources.src1.type = spooldir
etlAgent.sources.src1.type = com.gsta.bigdata.etl.flume.SpoolDirectoryCompressSource
etlAgent.sources.src1.spoolDir = /home/tianxq/etl/ztedata
etlAgent.sources.src1.batchSize=10000
etlAgent.sources.src1.deleteCompressFilePolicy=immediate
etlAgent.sources.src1.basenameHeader=true
etlAgent.sources.src1.interceptors = etlInterceptor

etlAgent.sources.src1.interceptors.etlInterceptor.type = com.gsta.bigdata.etl.flume.MultiProcessInterceptor$Builder
etlAgent.sources.src1.interceptors.etlInterceptor.configFilePath=./conf/lteup
etlAgent.sources.src1.interceptors.etlInterceptor.configFileName=ETL_LTEUP_HttpWap,ETL_LTEUP_Video
etlAgent.sources.src1.interceptors.etlInterceptor.fileNameHeaders=EXFODPI

# Describe the sink
etlAgent.sinks.sink1.type = hdfs
etlAgent.sinks.sink1.hdfs.path=/user/tianxq/flume
etlAgent.sinks.sink1.hdfs.filePrefix=%{p1}.%{p2}.%{year}.%{month}.%{day}.%{hour}
etlAgent.sinks.sink1.hdfs.fileSuffix=.txt
etlAgent.sinks.sink1.hdfs.rollSize=1073741824
etlAgent.sinks.sink1.hdfs.rollCount=0
etlAgent.sinks.sink1.hdfs.batchSize=10000
etlAgent.sinks.sink1.hdfs.fileType=DataStream 
etlAgent.sinks.sink1.hdfs.writeFormat=Text

# Use a channel which buffers events in memory
etlAgent.channels = ch1
etlAgent.channels.ch1.type = memory
etlAgent.channels.ch1.capacity = 100000
etlAgent.channels.ch1.transactionCapacity = 100000

# Bind the source and sink to the channel
etlAgent.sources.src1.channels = ch1
etlAgent.sinks.sink1.channel = ch1