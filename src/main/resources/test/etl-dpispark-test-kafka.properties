hosts=192.168.9.17,192.168.9.16,192.168.9.15
port=2181
brokers=/kafka80/brokers
topic=dpi-60-3r-0120
group=etl-consumer0420-1
consumerZK=192.168.9.17:2181,192.168.9.16:2181,192.168.9.15:2181
consumerZKPath=/spark-kafka-test
#every batch size=fetchsizebytes*(duration/fillfreqms)*receivesNum
#duration unit is second
duration=10
receivesNum=60
fetchsizebytes=1048576
#fetchsizebytes=2097152
fillfreqms=500
backpressure=true
proportional=0.75
integral=0.15
derivative=0
forcefromstart=false
chechPoint=true
#chkPointPath=hdfs\://192.168.9.16\:8020/data/spark/checkpoint
chkPointPath=hdfs\://dataface\:8020/data/spark/checkpoint
#0:MEMORY_ONLY 1:MEMORY_ONLY_2 2:MEMORY_ONLY_SER 
#3:MEMORY_ONLY_SER_2 4:MEMORY_AND_DISK 
#5:MEMORY_AND_DISK_2 6:MEMORY_AND_DISK_SER 7:MEMORY_AND_DISK_SER_2
storageLevel=2
#resultMode:hdfs or kafka
resultMode=kafka
outputKafkaBroker=192.168.9.80:9092,192.168.9.81:9092,192.168.9.80:9094,192.168.9.80:9093,192.168.9.81:9093,192.168.9.81:9094
outputTopic=dpi-result
#hdfs partition
partitionsNum=24
urlSuffixFile=conf/test/suffix-urlfilter.txt
#produce env
outputPath=hdfs\://192.168.9.16\:8020/data/spark/spark