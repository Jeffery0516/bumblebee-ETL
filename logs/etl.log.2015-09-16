2015-09-16 10:49:02 [main] WARN  DomainSocketFactory(116): The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2015-09-16 10:49:02 [main] INFO  MRRunner(268): path=/user/tianxq/output
2015-09-16 10:49:05 [main] INFO  MRRunner(271): delete  dir=/user/tianxq/output
2015-09-16 10:49:05 [main] INFO  MRRunner(268): path=/user/tianxq/output/error
2015-09-16 10:49:05 [main] INFO  ETLRunner(175): etl run result=-1
2015-09-16 10:51:55 [main] WARN  DomainSocketFactory(116): The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2015-09-16 10:51:55 [main] INFO  MRRunner(268): path=/user/tianxq/output
2015-09-16 10:51:55 [main] INFO  MRRunner(268): path=/user/tianxq/output/error
2015-09-16 10:51:56 [main] INFO  ETLRunner(175): etl run result=-1
2015-09-16 10:58:06 [main] WARN  DomainSocketFactory(116): The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2015-09-16 10:58:07 [main] INFO  MRRunner(268): path=/user/tianxq/output
2015-09-16 10:58:07 [main] INFO  MRRunner(268): path=/user/tianxq/output/error
2015-09-16 10:58:07 [main] WARN  NativeCodeLoader(62): Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-16 10:58:07 [main] INFO  deprecation(1049): session.id is deprecated. Instead, use dfs.metrics.session-id
2015-09-16 10:58:07 [main] INFO  JvmMetrics(76): Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-09-16 10:58:11 [main] WARN  JobSubmitter(261): No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-09-16 10:58:14 [main] INFO  FileInputFormat(281): Total input paths to process : 1
2015-09-16 10:58:15 [main] INFO  JobSubmitter(494): number of splits:1
2015-09-16 10:58:16 [main] INFO  JobSubmitter(583): Submitting tokens for job: job_local1229309577_0001
2015-09-16 10:58:17 [main] INFO  Job(1300): The url to track the job: http://localhost:8080/
2015-09-16 10:58:17 [main] INFO  Job(1345): Running job: job_local1229309577_0001
2015-09-16 10:58:17 [Thread-14] INFO  LocalJobRunner(471): OutputCommitter set in config null
2015-09-16 10:58:17 [Thread-14] INFO  LocalJobRunner(489): OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-09-16 10:58:17 [Thread-14] INFO  LocalJobRunner(448): Waiting for map tasks
2015-09-16 10:58:17 [LocalJobRunner Map Task Executor #0] INFO  LocalJobRunner(224): Starting task: attempt_local1229309577_0001_m_000000_0
2015-09-16 10:58:17 [LocalJobRunner Map Task Executor #0] INFO  ProcfsBasedProcessTree(181): ProcfsBasedProcessTree currently is supported only on Linux.
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  Task(587):  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@122e566
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(753): Processing split: hdfs://10.17.35.120:8020/user/tianxq/tianxqdata/dpi.data:0+1220
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(1202): (EQUATOR) 0 kvi 26214396(104857584)
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(995): mapreduce.task.io.sort.mb: 100
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(996): soft limit at 83886080
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(997): bufstart = 0; bufvoid = 104857600
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(998): kvstart = 26214396; length = 6553600
2015-09-16 10:58:18 [main] INFO  Job(1366): Job job_local1229309577_0001 running in uber mode : false
2015-09-16 10:58:18 [LocalJobRunner Map Task Executor #0] INFO  MapTask(402): Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-09-16 10:58:18 [main] INFO  Job(1373):  map 0% reduce 0%
2015-09-16 10:58:21 [LocalJobRunner Map Task Executor #0] INFO  LocalJobRunner(591): 
2015-09-16 10:58:21 [LocalJobRunner Map Task Executor #0] INFO  MapTask(1457): Starting flush of map output
2015-09-16 10:58:21 [LocalJobRunner Map Task Executor #0] INFO  MapTask(1475): Spilling map output
2015-09-16 10:58:21 [LocalJobRunner Map Task Executor #0] INFO  MapTask(1476): bufstart = 0; bufend = 1274; bufvoid = 104857600
2015-09-16 10:58:21 [LocalJobRunner Map Task Executor #0] INFO  MapTask(1478): kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2015-09-16 10:58:22 [LocalJobRunner Map Task Executor #0] INFO  MapTask(1660): Finished spill 0
2015-09-16 10:58:22 [LocalJobRunner Map Task Executor #0] INFO  Task(1001): Task:attempt_local1229309577_0001_m_000000_0 is done. And is in the process of committing
2015-09-16 10:58:22 [LocalJobRunner Map Task Executor #0] INFO  LocalJobRunner(591): map
2015-09-16 10:58:22 [LocalJobRunner Map Task Executor #0] INFO  Task(1121): Task 'attempt_local1229309577_0001_m_000000_0' done.
2015-09-16 10:58:22 [LocalJobRunner Map Task Executor #0] INFO  LocalJobRunner(249): Finishing task: attempt_local1229309577_0001_m_000000_0
2015-09-16 10:58:22 [Thread-14] INFO  LocalJobRunner(456): map task executor complete.
2015-09-16 10:58:22 [Thread-14] INFO  LocalJobRunner(448): Waiting for reduce tasks
2015-09-16 10:58:22 [pool-8-thread-1] INFO  LocalJobRunner(302): Starting task: attempt_local1229309577_0001_r_000000_0
2015-09-16 10:58:22 [pool-8-thread-1] INFO  ProcfsBasedProcessTree(181): ProcfsBasedProcessTree currently is supported only on Linux.
2015-09-16 10:58:22 [pool-8-thread-1] INFO  Task(587):  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b0c54b
2015-09-16 10:58:22 [pool-8-thread-1] INFO  ReduceTask(362): Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d7331a
2015-09-16 10:58:22 [main] INFO  Job(1373):  map 100% reduce 0%
2015-09-16 10:58:22 [pool-8-thread-1] INFO  MergeManagerImpl(196): MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-09-16 10:58:22 [EventFetcher for fetching Map Completion Events] INFO  EventFetcher(61): attempt_local1229309577_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-09-16 10:58:22 [localfetcher#1] INFO  LocalFetcher(141): localfetcher#1 about to shuffle output of map attempt_local1229309577_0001_m_000000_0 decomp: 1284 len: 1288 to MEMORY
2015-09-16 10:58:22 [localfetcher#1] INFO  InMemoryMapOutput(100): Read 1284 bytes from map-output for attempt_local1229309577_0001_m_000000_0
2015-09-16 10:58:22 [localfetcher#1] INFO  MergeManagerImpl(314): closeInMemoryFile -> map-output of size: 1284, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1284
2015-09-16 10:58:22 [EventFetcher for fetching Map Completion Events] INFO  EventFetcher(76): EventFetcher is interrupted.. Returning
2015-09-16 10:58:22 [pool-8-thread-1] INFO  LocalJobRunner(591): 1 / 1 copied.
2015-09-16 10:58:22 [pool-8-thread-1] INFO  MergeManagerImpl(674): finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2015-09-16 10:58:22 [pool-8-thread-1] INFO  Merger(597): Merging 1 sorted segments
2015-09-16 10:58:22 [pool-8-thread-1] INFO  Merger(696): Down to the last merge-pass, with 1 segments left of total size: 1279 bytes
2015-09-16 10:58:22 [pool-8-thread-1] INFO  MergeManagerImpl(751): Merged 1 segments, 1284 bytes to disk to satisfy reduce memory limit
2015-09-16 10:58:22 [pool-8-thread-1] INFO  MergeManagerImpl(781): Merging 1 files, 1288 bytes from disk
2015-09-16 10:58:23 [pool-8-thread-1] INFO  MergeManagerImpl(796): Merging 0 segments, 0 bytes from memory into reduce
2015-09-16 10:58:23 [pool-8-thread-1] INFO  Merger(597): Merging 1 sorted segments
2015-09-16 10:58:23 [pool-8-thread-1] INFO  Merger(696): Down to the last merge-pass, with 1 segments left of total size: 1279 bytes
2015-09-16 10:58:23 [pool-8-thread-1] INFO  LocalJobRunner(591): 1 / 1 copied.
2015-09-16 10:58:23 [pool-8-thread-1] INFO  deprecation(1049): mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2015-09-16 10:58:23 [pool-8-thread-1] INFO  Task(1001): Task:attempt_local1229309577_0001_r_000000_0 is done. And is in the process of committing
2015-09-16 10:58:23 [pool-8-thread-1] INFO  LocalJobRunner(591): 1 / 1 copied.
2015-09-16 10:58:23 [pool-8-thread-1] INFO  Task(1162): Task attempt_local1229309577_0001_r_000000_0 is allowed to commit now
2015-09-16 10:58:23 [pool-8-thread-1] INFO  FileOutputCommitter(439): Saved output of task 'attempt_local1229309577_0001_r_000000_0' to hdfs://10.17.35.120:8020/user/tianxq/output/_temporary/0/task_local1229309577_0001_r_000000
2015-09-16 10:58:23 [pool-8-thread-1] INFO  LocalJobRunner(591): reduce > reduce
2015-09-16 10:58:23 [pool-8-thread-1] INFO  Task(1121): Task 'attempt_local1229309577_0001_r_000000_0' done.
2015-09-16 10:58:23 [pool-8-thread-1] INFO  LocalJobRunner(325): Finishing task: attempt_local1229309577_0001_r_000000_0
2015-09-16 10:58:23 [Thread-14] INFO  LocalJobRunner(456): reduce task executor complete.
2015-09-16 10:58:24 [main] INFO  Job(1373):  map 100% reduce 100%
2015-09-16 10:58:24 [main] INFO  Job(1384): Job job_local1229309577_0001 completed successfully
2015-09-16 10:58:24 [main] INFO  Job(1391): Counters: 38
	File System Counters
		FILE: Number of bytes read=2984
		FILE: Number of bytes written=579364
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2440
		HDFS: Number of bytes written=1268
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=3
		Map output records=2
		Map output bytes=1274
		Map output materialized bytes=1288
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1288
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=121
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1220
	File Output Format Counters 
		Bytes Written=1268
2015-09-16 10:58:24 [main] INFO  MRRunner(201): ==============error information===========
2015-09-16 10:58:24 [main] INFO  MRRunner(279): ================job information===========
2015-09-16 10:58:24 [main] INFO  MRRunner(281): job name: gzdpi
2015-09-16 10:58:24 [main] INFO  MRRunner(282): job success:yes
2015-09-16 10:58:24 [main] INFO  MRRunner(287): total lines:3
2015-09-16 10:58:24 [main] INFO  MRRunner(292): output lines: 2
2015-09-16 10:58:24 [main] INFO  MRRunner(295): error lines: 1
2015-09-16 10:58:24 [main] INFO  MRRunner(297): begin time: 2015-09-16 10:58:01
2015-09-16 10:58:24 [main] INFO  MRRunner(298): end time: 2015-09-16 10:58:24
2015-09-16 10:58:24 [main] INFO  MRRunner(300): cost time: 23 seconds
2015-09-16 15:47:13 [main] WARN  DomainSocketFactory(116): The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2015-09-16 15:47:14 [main] INFO  MRRunner(267): path=/user/tianxq/output
2015-09-16 15:47:15 [main] INFO  MRRunner(267): path=/user/tianxq/output/error
2015-09-16 15:47:15 [main] WARN  NativeCodeLoader(62): Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-16 15:47:15 [main] INFO  deprecation(1049): session.id is deprecated. Instead, use dfs.metrics.session-id
2015-09-16 15:47:15 [main] INFO  JvmMetrics(76): Initializing JVM Metrics with processName=JobTracker, sessionId=
